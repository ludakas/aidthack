{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               252672    \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 100, 128)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, None, 128)         197376    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, None, 200)         25800     \n",
      "=================================================================\n",
      "Total params: 475,848\n",
      "Trainable params: 475,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM_output (LSTM)           (None, 128)               168448    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               25800     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 200)               0         \n",
      "=================================================================\n",
      "Total params: 194,248\n",
      "Trainable params: 194,248\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.models.Sequential at 0x7fdf8bd3f9e8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from itertools import chain\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.python.keras.layers import GRU, LSTM, Input, Dense, TimeDistributed\n",
    "from tensorflow.python.keras.models import Model, Sequential\n",
    "from tensorflow.python.keras.layers import Activation, SimpleRNN\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.losses import sparse_categorical_crossentropy, mean_squared_error\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "from tensorflow.python.keras.layers import RepeatVector\n",
    "from tensorflow.python.keras.layers import Bidirectional\n",
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "from tensorflow.python.keras import backend\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "\n",
    "ed_lr = 0.1\n",
    "ed_lr_dec = 1/10\n",
    "ed_batch_size = 1024\n",
    "ed_epochs = 25\n",
    "\n",
    "def encoder_decoder_model(input_shape, cell_units=128, layers=1, learning_rate=0.1,\n",
    "          activation='tanh', dropout=0.5, batch_norm=False):\n",
    "    \"\"\"\n",
    "    Build and train a bidirectional RNN model on x and y\n",
    "    :param input_shape: (sequence_length, embedding size)\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    encoder = input_layer\n",
    "    for _ in range(layers - 1):\n",
    "        encoder = Bidirectional(\n",
    "                GRU(cell_units, return_sequences=True, activation=activation, dropout=dropout),\n",
    "                merge_mode='ave', weights=None)(encoder)\n",
    "        if batch_norm:\n",
    "            BatchNormalization()(encoder)\n",
    "\n",
    "    encoder = Bidirectional(\n",
    "                GRU(cell_units, return_sequences=False,\n",
    "                    activation=activation, dropout=dropout,\n",
    "                    name='encoder_output'),\n",
    "                merge_mode='ave', weights=None)(encoder)\n",
    "\n",
    "    repeat = RepeatVector(input_shape[0])(encoder)\n",
    "\n",
    "    decoder = repeat\n",
    "    for _ in range(layers):\n",
    "        decoder = Bidirectional(\n",
    "                GRU(cell_units, return_sequences=True, activation=activation, dropout=dropout),\n",
    "                merge_mode='ave', weights=None)(decoder)\n",
    "        if batch_norm:\n",
    "            BatchNormalization()(decoder)\n",
    "\n",
    "    predictions = Dense(input_shape[1], activation='softmax')(decoder)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=predictions)\n",
    "    model.compile(loss=mean_squared_error,\n",
    "                  optimizer=Adam(ed_lr, ed_lr_dec),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def simple_model(input_shape, cell_units=128):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(cell_units, input_shape=input_shape, name='LSTM_output'))\n",
    "    model.add(Dense(input_shape[1]))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "\n",
    "    # initialize optimizer\n",
    "    optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "    # compile model --> make sure initialized optimizer and callbacks - as defined above - are used\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "ed_model = encoder_decoder_model((100, 200))\n",
    "simple_model((100, 200))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def tokenize(x):\n",
    "    \"\"\"\n",
    "    Tokenize x\n",
    "    :param x: List of sentences/strings to be tokenized\n",
    "    :return: Tuple of (tokenized x data, tokenizer used to tokenize x)\n",
    "    \"\"\"\n",
    "    small_voc_tokenizer = Tokenizer(filters='')\n",
    "    small_voc_tokenizer.fit_on_texts(iter(english_sentences))\n",
    "\n",
    "    return small_voc_tokenizer.texts_to_sequences(x), small_voc_tokenizer\n",
    "\n",
    "def pad(x, length=None):\n",
    "    \"\"\"\n",
    "    Pad x\n",
    "    :param x: List of sequences.\n",
    "    :param length: Length to pad the sequence to.  If None, use length of longest sequence in x.\n",
    "    :return: Padded numpy array of sequences\n",
    "    \"\"\"\n",
    "    maxlen = length if length else max(len(seq) for seq in x)\n",
    "\n",
    "    return pad_sequences(x, maxlen=maxlen, padding='post', truncating='post', value=0)\n",
    "\n",
    "\n",
    "def preprocess(x, y):\n",
    "    \"\"\"\n",
    "    Preprocess x and y\n",
    "    :param x: Feature List of sentences\n",
    "    :param y: Label List of sentences\n",
    "    :return: Tuple of (Preprocessed x, Preprocessed y, x tokenizer, y tokenizer)\n",
    "    \"\"\"\n",
    "    preprocess_x, x_tk = tokenize(x)\n",
    "    preprocess_y, y_tk = tokenize(y)\n",
    "\n",
    "    preprocess_x = pad(preprocess_x)\n",
    "    preprocess_y = pad(preprocess_y)\n",
    "\n",
    "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
    "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
    "\n",
    "    return preprocess_x, preprocess_y, x_tk, y_tk\n",
    "\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\"\n",
    "    Load dataset\n",
    "    \"\"\"\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file, \"r\") as f:\n",
    "        data = f.read()\n",
    "\n",
    "    return data.split('\\n')\n",
    "\n",
    "\n",
    "def logits_to_text(logits, tokenizer):\n",
    "    \"\"\"\n",
    "    Turn logits from a neural network into text using the tokenizer\n",
    "    :param logits: Logits from a neural network\n",
    "    :param tokenizer: Keras Tokenizer fit on the labels\n",
    "    :return: String that represents the text of the logits\n",
    "    \"\"\"\n",
    "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = '<PAD>'\n",
    "\n",
    "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Load English data\n",
    "english_sentences = load_data('small_vocab_en')\n",
    "\n",
    "print('Dataset Loaded')\n",
    "\n",
    "# Tokenize Example output\n",
    "text_sentences = [\n",
    "    'The quick brown fox jumps over the lazy dog .',\n",
    "    'By Jove , my quick study of lexicography won a prize .',\n",
    "    'This is a short sentence .']\n",
    "text_tokenized, text_tokenizer = tokenize(text_sentences)\n",
    "print(text_tokenizer.word_index)\n",
    "print()\n",
    "for sample_i, (sent, token_sent) in enumerate(zip(text_sentences, text_tokenized)):\n",
    "    print('Sequence {} in x'.format(sample_i + 1))\n",
    "    print('  Input:  {}'.format(sent))\n",
    "    print('  Output: {}'.format(token_sent))\n",
    "\n",
    "\n",
    "# Pad Tokenized output\n",
    "test_pad = pad(text_tokenized)\n",
    "for sample_i, (token_sent, pad_sent) in enumerate(zip(text_tokenized, test_pad)):\n",
    "    print('Sequence {} in x'.format(sample_i + 1))\n",
    "    print('  Input:  {}'.format(np.array(token_sent)))\n",
    "    print('  Output: {}'.format(pad_sent))\n",
    "\n",
    "\n",
    "preproc_english_sentences, preproc_french_sentences, english_tokenizer, _ =\\\n",
    "    preprocess(english_sentences, english_sentences)\n",
    "\n",
    "print('Data Preprocessed')\n",
    "\n",
    "\n",
    "# Reshaping the input to work with a basic RNN\n",
    "pad_x = pad(preproc_english_sentences, preproc_english_sentences.shape[1])\n",
    "\n",
    "onehot_x = np.empty(pad_x.shape + (len(english_tokenizer.word_index) + 1, ))\n",
    "for i in range(pad_x.shape[0]):\n",
    "    onehot_x[i] = to_categorical(pad_x[i], num_classes=len(english_tokenizer.word_index) + 1)\n",
    "               \n",
    "print(onehot_x.shape)\n",
    "# # Using one-hot encoding to get simple RNN to work\n",
    "# onehot_x = np.apply_along_axis(lambda x: to_categorical(x, num_classes=len(english_tokenizer.word_index) + 1), 1, pad_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 372,\n",
      " 'ab': 196,\n",
      " 'abend': 774,\n",
      " 'abl': 902,\n",
      " 'abruf': 946,\n",
      " 'abschlie': 626,\n",
      " 'account': 858,\n",
      " 'adapter': 773,\n",
      " 'adresse': 72,\n",
      " 'adressen': 590,\n",
      " 'aktuell': 233,\n",
      " 'aktuellen': 733,\n",
      " 'alex': 716,\n",
      " 'all': 821,\n",
      " 'alle': 47,\n",
      " 'allem': 629,\n",
      " 'allen': 280,\n",
      " 'allerdings': 98,\n",
      " 'alles': 10,\n",
      " 'also': 12,\n",
      " 'alte': 668,\n",
      " 'alten': 349,\n",
      " 'alternativ': 952,\n",
      " 'alternative': 715,\n",
      " 'analog': 751,\n",
      " 'analoge': 691,\n",
      " 'analoges': 935,\n",
      " 'anbieten': 611,\n",
      " 'anbieter': 296,\n",
      " 'and': 909,\n",
      " 'andere': 164,\n",
      " 'anderem': 936,\n",
      " 'anderen': 51,\n",
      " 'anderes': 621,\n",
      " 'anders': 434,\n",
      " 'andre': 855,\n",
      " 'android': 511,\n",
      " 'anfang': 505,\n",
      " 'anfrage': 991,\n",
      " 'angeblich': 744,\n",
      " 'angebot': 675,\n",
      " 'angeboten': 274,\n",
      " 'angek': 851,\n",
      " 'angekommen': 532,\n",
      " 'angerufen': 370,\n",
      " 'angeschlossen': 628,\n",
      " 'angezeigt': 588,\n",
      " 'anhand': 913,\n",
      " 'anlage': 327,\n",
      " 'anlagenanschluss': 337,\n",
      " 'anleitung': 705,\n",
      " 'anliegen': 206,\n",
      " 'anruf': 397,\n",
      " 'anrufe': 545,\n",
      " 'anrufen': 922,\n",
      " 'anscheinend': 770,\n",
      " 'anschl': 133,\n",
      " 'anschlie': 517,\n",
      " 'anschlu': 579,\n",
      " 'anschlusses': 863,\n",
      " 'ansehen': 850,\n",
      " 'ansonsten': 699,\n",
      " 'antrag': 797,\n",
      " 'antwort': 27,\n",
      " 'antworten': 475,\n",
      " 'app': 556,\n",
      " 'apple': 491,\n",
      " 'april': 945,\n",
      " 'arbeiten': 313,\n",
      " 'au': 468,\n",
      " 'aufgrund': 792,\n",
      " 'auftrag': 145,\n",
      " 'auftragsbest': 421,\n",
      " 'ausf': 419,\n",
      " 'ausgef': 248,\n",
      " 'auskunft': 784,\n",
      " 'aussage': 635,\n",
      " 'aussagen': 957,\n",
      " 'ausschlie': 927,\n",
      " 'automatisch': 633,\n",
      " 'b': 73,\n",
      " 'bach': 940,\n",
      " 'bald': 670,\n",
      " 'basic': 967,\n",
      " 'basierten': 494,\n",
      " 'beachten': 652,\n",
      " 'beantworten': 837,\n",
      " 'bearbeitet': 805,\n",
      " 'bearbeitung': 723,\n",
      " 'beauftragen': 815,\n",
      " 'beauftragt': 857,\n",
      " 'begr': 543,\n",
      " 'behalten': 962,\n",
      " 'beiden': 620,\n",
      " 'beim': 131,\n",
      " 'beitr': 692,\n",
      " 'beitrag': 277,\n",
      " 'bekannt': 473,\n",
      " 'bekomme': 300,\n",
      " 'bekommen': 61,\n",
      " 'bekommt': 452,\n",
      " 'ben': 117,\n",
      " 'beraten': 941,\n",
      " 'berblick': 895,\n",
      " 'berechnet': 834,\n",
      " 'bereich': 411,\n",
      " 'bereits': 45,\n",
      " 'berhaupt': 306,\n",
      " 'berlin': 586,\n",
      " 'bernahme': 583,\n",
      " 'bernommen': 662,\n",
      " 'berpr': 700,\n",
      " 'bescheid': 572,\n",
      " 'besprochen': 872,\n",
      " 'besser': 392,\n",
      " 'best': 160,\n",
      " 'beste': 660,\n",
      " 'besteht': 498,\n",
      " 'bestellen': 578,\n",
      " 'bestellt': 487,\n",
      " 'bestellung': 734,\n",
      " 'besten': 401,\n",
      " 'bestimmt': 741,\n",
      " 'bestimmte': 891,\n",
      " 'biete': 667,\n",
      " 'bieten': 428,\n",
      " 'bietet': 552,\n",
      " 'bin': 14,\n",
      " 'bis': 30,\n",
      " 'bisher': 221,\n",
      " 'bisherigen': 625,\n",
      " 'bist': 929,\n",
      " 'bitten': 982,\n",
      " 'bl': 759,\n",
      " 'bleiben': 678,\n",
      " 'bleibt': 808,\n",
      " 'box': 708,\n",
      " 'brauche': 685,\n",
      " 'brauchen': 396,\n",
      " 'brigens': 657,\n",
      " 'bringen': 724,\n",
      " 'bsp': 585,\n",
      " 'bspw': 536,\n",
      " 'buchbar': 868,\n",
      " 'buchen': 321,\n",
      " 'bundesnetzagentur': 515,\n",
      " 'businessbasic': 381,\n",
      " 'button': 838,\n",
      " 'bzw': 75,\n",
      " 'c': 608,\n",
      " 'ca': 497,\n",
      " 'call': 363,\n",
      " 'callcenter': 912,\n",
      " 'ch': 499,\n",
      " 'che': 283,\n",
      " 'chlich': 303,\n",
      " 'chst': 465,\n",
      " 'chsten': 462,\n",
      " 'chte': 83,\n",
      " 'chten': 168,\n",
      " 'ck': 156,\n",
      " 'ckmeldung': 190,\n",
      " 'ckruf': 697,\n",
      " 'com': 870,\n",
      " 'combicard': 886,\n",
      " 'comfort': 310,\n",
      " 'compact': 636,\n",
      " 'companyconnect': 704,\n",
      " 'complete': 114,\n",
      " 'connect': 284,\n",
      " 'cti': 582,\n",
      " 'd': 115,\n",
      " 'dabei': 189,\n",
      " 'dadurch': 816,\n",
      " 'daf': 110,\n",
      " 'daher': 223,\n",
      " 'damen': 765,\n",
      " 'damit': 17,\n",
      " 'danach': 584,\n",
      " 'danke': 1,\n",
      " 'dar': 794,\n",
      " 'daran': 461,\n",
      " 'darauf': 355,\n",
      " 'darf': 592,\n",
      " 'darum': 721,\n",
      " 'data': 956,\n",
      " 'datenschutzgr': 290,\n",
      " 'datenvolumen': 939,\n",
      " 'davinci': 760,\n",
      " 'davon': 264,\n",
      " 'dazu': 53,\n",
      " 'de': 19,\n",
      " 'dein': 454,\n",
      " 'deine': 373,\n",
      " 'deinem': 814,\n",
      " 'deinen': 544,\n",
      " 'deiner': 937,\n",
      " 'denke': 564,\n",
      " 'denken': 908,\n",
      " 'derzeit': 249,\n",
      " 'des': 0,\n",
      " 'deswegen': 847,\n",
      " 'deutsche': 569,\n",
      " 'deutschen': 606,\n",
      " 'deutschland': 637,\n",
      " 'deutschlandlan': 149,\n",
      " 'dich': 216,\n",
      " 'dienst': 757,\n",
      " 'dies': 97,\n",
      " 'diesem': 261,\n",
      " 'diesen': 217,\n",
      " 'dieser': 46,\n",
      " 'dieses': 180,\n",
      " 'dir': 144,\n",
      " 'direkt': 195,\n",
      " 'doch': 55,\n",
      " 'dort': 108,\n",
      " 'dr': 525,\n",
      " 'drei': 654,\n",
      " 'dringend': 926,\n",
      " 'dsl': 87,\n",
      " 'durch': 140,\n",
      " 'durchgef': 998,\n",
      " 'eben': 460,\n",
      " 'ebenfalls': 439,\n",
      " 'edvf': 151,\n",
      " 'egal': 865,\n",
      " 'eher': 404,\n",
      " 'eigenen': 694,\n",
      " 'eigentlich': 241,\n",
      " 'einer': 29,\n",
      " 'eines': 239,\n",
      " 'einfach': 65,\n",
      " 'eingestellt': 951,\n",
      " 'einige': 422,\n",
      " 'einigen': 423,\n",
      " 'einloggen': 964,\n",
      " 'einmal': 59,\n",
      " 'einmaligen': 961,\n",
      " 'einrichten': 417,\n",
      " 'einschr': 914,\n",
      " 'einstellen': 910,\n",
      " 'einstellungen': 294,\n",
      " 'email': 562,\n",
      " 'empfehlen': 801,\n",
      " 'en': 92,\n",
      " 'end': 659,\n",
      " 'ende': 476,\n",
      " 'endger': 369,\n",
      " 'endlich': 489,\n",
      " 'entertain': 793,\n",
      " 'entfernt': 653,\n",
      " 'entscheiden': 874,\n",
      " 'entschuldigen': 877,\n",
      " 'entschuldigung': 607,\n",
      " 'entsprechende': 832,\n",
      " 'entsprechenden': 463,\n",
      " 'entweder': 728,\n",
      " 'er': 34,\n",
      " 'erf': 947,\n",
      " 'erfahrungen': 351,\n",
      " 'erfolg': 449,\n",
      " 'erfolgreich': 971,\n",
      " 'ergebnis': 663,\n",
      " 'erh': 502,\n",
      " 'erhalten': 35,\n",
      " 'erkl': 268,\n",
      " 'erledigt': 574,\n",
      " 'erneut': 644,\n",
      " 'erreichbar': 451,\n",
      " 'erreichen': 548,\n",
      " 'erreicht': 710,\n",
      " 'error': 776,\n",
      " 'erscheint': 888,\n",
      " 'erst': 81,\n",
      " 'erste': 488,\n",
      " 'ersten': 387,\n",
      " 'erstmal': 783,\n",
      " 'etwas': 39,\n",
      " 'eur': 810,\n",
      " 'euro': 368,\n",
      " 'eventuell': 904,\n",
      " 'exchange': 518,\n",
      " 'experten': 879,\n",
      " 'extra': 758,\n",
      " 'fabian': 111,\n",
      " 'fall': 104,\n",
      " 'falls': 259,\n",
      " 'falsche': 658,\n",
      " 'fast': 402,\n",
      " 'fax': 192,\n",
      " 'faxe': 780,\n",
      " 'faxen': 614,\n",
      " 'faxger': 559,\n",
      " 'feedback': 311,\n",
      " 'fehler': 269,\n",
      " 'fehlermeldung': 703,\n",
      " 'fen': 384,\n",
      " 'feste': 155,\n",
      " 'fester': 684,\n",
      " 'festnetz': 200,\n",
      " 'ffentlich': 514,\n",
      " 'ffentlicht': 918,\n",
      " 'ffnen': 985,\n",
      " 'finde': 293,\n",
      " 'finden': 119,\n",
      " 'firma': 227,\n",
      " 'flat': 386,\n",
      " 'florian': 78,\n",
      " 'florianschmidt': 844,\n",
      " 'folgende': 677,\n",
      " 'folgendes': 302,\n",
      " 'formular': 163,\n",
      " 'forum': 383,\n",
      " 'fr': 444,\n",
      " 'frage': 49,\n",
      " 'fragen': 170,\n",
      " 'freitag': 674,\n",
      " 'freue': 353,\n",
      " 'freuen': 425,\n",
      " 'freundlichen': 726,\n",
      " 'freut': 455,\n",
      " 'fritz': 605,\n",
      " 'fritzbox': 232,\n",
      " 'ft': 299,\n",
      " 'fts': 959,\n",
      " 'ftskunde': 538,\n",
      " 'ftskunden': 282,\n",
      " 'funktion': 804,\n",
      " 'funktionieren': 354,\n",
      " 'funktioniert': 38,\n",
      " 'g': 201,\n",
      " 'gab': 749,\n",
      " 'ganz': 102,\n",
      " 'ganze': 231,\n",
      " 'gar': 247,\n",
      " 'gb': 436,\n",
      " 'gbar': 307,\n",
      " 'gbarkeit': 923,\n",
      " 'ge': 152,\n",
      " 'geb': 686,\n",
      " 'gebe': 534,\n",
      " 'geben': 127,\n",
      " 'gebucht': 366,\n",
      " 'geduld': 840,\n",
      " 'gef': 563,\n",
      " 'gefunden': 243,\n",
      " 'gegeben': 550,\n",
      " 'gegen': 558,\n",
      " 'geh': 433,\n",
      " 'gehabt': 820,\n",
      " 'gehe': 785,\n",
      " 'gehen': 212,\n",
      " 'geholfen': 864,\n",
      " 'geht': 37,\n",
      " 'gek': 394,\n",
      " 'gekauft': 996,\n",
      " 'geklappt': 711,\n",
      " 'gekommen': 706,\n",
      " 'gel': 508,\n",
      " 'geld': 717,\n",
      " 'gelesen': 965,\n",
      " 'gemacht': 328,\n",
      " 'gemeinsam': 896,\n",
      " 'gemeldet': 712,\n",
      " 'gen': 314,\n",
      " 'genannt': 807,\n",
      " 'genau': 106,\n",
      " 'genauer': 655,\n",
      " 'genauso': 768,\n",
      " 'genutzt': 665,\n",
      " 'geplant': 900,\n",
      " 'ger': 42,\n",
      " 'gerade': 112,\n",
      " 'gern': 287,\n",
      " 'gerne': 40,\n",
      " 'gesagt': 258,\n",
      " 'geschaltet': 681,\n",
      " 'geschickt': 492,\n",
      " 'geschrieben': 827,\n",
      " 'geschwindigkeit': 272,\n",
      " 'gesehen': 738,\n",
      " 'gesetzt': 983,\n",
      " 'gespannt': 478,\n",
      " 'gespr': 193,\n",
      " 'gestellt': 540,\n",
      " 'gestern': 432,\n",
      " 'gew': 482,\n",
      " 'ggf': 507,\n",
      " 'gilt': 782,\n",
      " 'ging': 539,\n",
      " 'gl': 928,\n",
      " 'glaube': 546,\n",
      " 'gleich': 301,\n",
      " 'gleiche': 640,\n",
      " 'glich': 26,\n",
      " 'glichkeit': 252,\n",
      " 'glichkeiten': 639,\n",
      " 'google': 878,\n",
      " 'grade': 969,\n",
      " 'gro': 270,\n",
      " 'gru': 3,\n",
      " 'grund': 385,\n",
      " 'gruss': 742,\n",
      " 'gt': 453,\n",
      " 'gung': 237,\n",
      " 'gut': 118,\n",
      " 'gute': 414,\n",
      " 'guten': 32,\n",
      " 'h': 5,\n",
      " 'hab': 415,\n",
      " 'halte': 943,\n",
      " 'halten': 547,\n",
      " 'handelt': 854,\n",
      " 'handy': 254,\n",
      " 'hardware': 830,\n",
      " 'hast': 142,\n",
      " 'hatte': 124,\n",
      " 'hatten': 622,\n",
      " 'haus': 610,\n",
      " 'he': 892,\n",
      " 'hei': 378,\n",
      " 'helfen': 159,\n",
      " 'hen': 755,\n",
      " 'her': 234,\n",
      " 'here': 788,\n",
      " 'herr': 753,\n",
      " 'herzlich': 158,\n",
      " 'herzlichen': 603,\n",
      " 'heute': 54,\n",
      " 'hey': 915,\n",
      " 'hi': 598,\n",
      " 'hierzu': 509,\n",
      " 'hilfe': 94,\n",
      " 'hilfreich': 960,\n",
      " 'hilft': 116,\n",
      " 'hin': 441,\n",
      " 'hinterlegt': 800,\n",
      " 'hinweis': 364,\n",
      " 'hlen': 795,\n",
      " 'hlt': 567,\n",
      " 'hoffe': 230,\n",
      " 'homepage': 934,\n",
      " 'hometalk': 992,\n",
      " 'hotline': 138,\n",
      " 'hr': 630,\n",
      " 'hren': 413,\n",
      " 'hrt': 265,\n",
      " 'hsp': 772,\n",
      " 'html': 906,\n",
      " 'https': 420,\n",
      " 'hubert': 367,\n",
      " 'idee': 526,\n",
      " 'ihn': 472,\n",
      " 'ihr': 4,\n",
      " 'ihrem': 120,\n",
      " 'ihren': 90,\n",
      " 'ihrer': 177,\n",
      " 'ihres': 977,\n",
      " 'immer': 18,\n",
      " 'info': 316,\n",
      " 'information': 839,\n",
      " 'informationen': 273,\n",
      " 'informiert': 631,\n",
      " 'infos': 687,\n",
      " 'inkl': 672,\n",
      " 'innerhalb': 601,\n",
      " 'ins': 407,\n",
      " 'interesse': 767,\n",
      " 'intern': 968,\n",
      " 'internet': 67,\n",
      " 'iphone': 154,\n",
      " 'ipv': 339,\n",
      " 'irina': 602,\n",
      " 'isdn': 79,\n",
      " 'it': 966,\n",
      " 'j': 70,\n",
      " 'jahr': 262,\n",
      " 'jahre': 811,\n",
      " 'jahren': 357,\n",
      " 'jahres': 942,\n",
      " 'jdzpzy': 271,\n",
      " 'jeden': 921,\n",
      " 'jedoch': 228,\n",
      " 'jemand': 125,\n",
      " 'juni': 988,\n",
      " 'kabel': 852,\n",
      " 'kam': 595,\n",
      " 'kannst': 225,\n",
      " 'karte': 365,\n",
      " 'kaufen': 919,\n",
      " 'kein': 25,\n",
      " 'keinen': 184,\n",
      " 'keiner': 448,\n",
      " 'kl': 379,\n",
      " 'klappt': 537,\n",
      " 'klar': 358,\n",
      " 'kleine': 766,\n",
      " 'knapp': 999,\n",
      " 'kollege': 798,\n",
      " 'kollegen': 162,\n",
      " 'kollegin': 619,\n",
      " 'komme': 901,\n",
      " 'kommen': 181,\n",
      " 'kommt': 128,\n",
      " 'komplett': 859,\n",
      " 'konnte': 244,\n",
      " 'konnten': 533,\n",
      " 'kontakt': 688,\n",
      " 'kontaktformular': 16,\n",
      " 'korrekt': 869,\n",
      " 'kosten': 276,\n",
      " 'kostenfrei': 853,\n",
      " 'kostet': 312,\n",
      " 'kunde': 224,\n",
      " 'kunden': 66,\n",
      " 'kundencenter': 178,\n",
      " 'kundendaten': 496,\n",
      " 'kundennummer': 575,\n",
      " 'kurz': 427,\n",
      " 'laden': 954,\n",
      " 'lang': 589,\n",
      " 'lange': 446,\n",
      " 'laptop': 958,\n",
      " 'lassen': 85,\n",
      " 'laufen': 519,\n",
      " 'laufenden': 861,\n",
      " 'laut': 335,\n",
      " 'lediglich': 542,\n",
      " 'leid': 632,\n",
      " 'leistungen': 970,\n",
      " 'leitung': 141,\n",
      " 'leitungen': 612,\n",
      " 'letzten': 522,\n",
      " 'liegen': 408,\n",
      " 'liegt': 130,\n",
      " 'link': 89,\n",
      " 'llen': 161,\n",
      " 'llig': 752,\n",
      " 'llt': 185,\n",
      " 'los': 802,\n",
      " 'lt': 390,\n",
      " 'lte': 255,\n",
      " 'machen': 147,\n",
      " 'macht': 286,\n",
      " 'mail': 23,\n",
      " 'mails': 246,\n",
      " 'mb': 599,\n",
      " 'mbit': 347,\n",
      " 'mehrere': 746,\n",
      " 'mehrfach': 841,\n",
      " 'mein': 57,\n",
      " 'meine': 15,\n",
      " 'meinem': 198,\n",
      " 'meinen': 84,\n",
      " 'meiner': 215,\n",
      " 'meines': 963,\n",
      " 'melde': 405,\n",
      " 'melden': 109,\n",
      " 'mfg': 824,\n",
      " 'microsoft': 829,\n",
      " 'milen': 617,\n",
      " 'minuten': 730,\n",
      " 'mitarbeiter': 148,\n",
      " 'mitarbeiterin': 899,\n",
      " 'mitarbeitern': 791,\n",
      " 'mitgeteilt': 648,\n",
      " 'mittlerweile': 418,\n",
      " 'mlich': 470,\n",
      " 'mobil': 340,\n",
      " 'mobile': 330,\n",
      " 'mobilfunk': 555,\n",
      " 'modem': 380,\n",
      " 'momentan': 549,\n",
      " 'monat': 521,\n",
      " 'monate': 529,\n",
      " 'monaten': 513,\n",
      " 'monatlich': 520,\n",
      " 'montag': 506,\n",
      " 'morgen': 41,\n",
      " 'multisim': 424,\n",
      " 'muss': 6,\n",
      " 'musste': 727,\n",
      " 'mwst': 813,\n",
      " 'nachdem': 458,\n",
      " 'nachfrage': 953,\n",
      " 'nachfragen': 731,\n",
      " 'nachricht': 450,\n",
      " 'nachvollziehen': 763,\n",
      " 'nat': 137,\n",
      " 'nden': 187,\n",
      " 'ndern': 374,\n",
      " 'ndert': 500,\n",
      " 'nderung': 812,\n",
      " 'ndig': 485,\n",
      " 'ndigt': 275,\n",
      " 'ndigung': 319,\n",
      " 'ndlich': 649,\n",
      " 'ndnis': 976,\n",
      " 'ne': 718,\n",
      " 'nehmen': 342,\n",
      " 'nein': 876,\n",
      " 'nennen': 541,\n",
      " 'nes': 484,\n",
      " 'netcologne': 504,\n",
      " 'nett': 729,\n",
      " 'netto': 761,\n",
      " 'netz': 393,\n",
      " 'neu': 263,\n",
      " 'neue': 191,\n",
      " 'neuen': 36,\n",
      " 'neuer': 308,\n",
      " 'neues': 325,\n",
      " 'nftig': 581,\n",
      " 'ngern': 735,\n",
      " 'ngerung': 483,\n",
      " 'ngt': 565,\n",
      " 'nichts': 64,\n",
      " 'nie': 673,\n",
      " 'niemand': 566,\n",
      " 'nix': 866,\n",
      " 'nlich': 898,\n",
      " 'nlichen': 551,\n",
      " 'nnte': 207,\n",
      " 'nnten': 790,\n",
      " 'nochmal': 469,\n",
      " 'normal': 825,\n",
      " 'nsche': 493,\n",
      " 'ntba': 725,\n",
      " 'nummer': 235,\n",
      " 'nummern': 764,\n",
      " 'nun': 8,\n",
      " 'nutze': 490,\n",
      " 'nutzen': 33,\n",
      " 'nutzer': 576,\n",
      " 'o': 871,\n",
      " 'oben': 732,\n",
      " 'obwohl': 719,\n",
      " 'octopus': 680,\n",
      " 'office': 894,\n",
      " 'offiziell': 916,\n",
      " 'ohne': 68,\n",
      " 'ok': 320,\n",
      " 'oktober': 789,\n",
      " 'online': 69,\n",
      " 'option': 253,\n",
      " 'ort': 642,\n",
      " 'outlook': 570,\n",
      " 'p': 426,\n",
      " 'paar': 245,\n",
      " 'pass': 860,\n",
      " 'passieren': 974,\n",
      " 'passiert': 375,\n",
      " 'passwort': 819,\n",
      " 'pc': 736,\n",
      " 'pcs': 806,\n",
      " 'pdf': 882,\n",
      " 'per': 96,\n",
      " 'pers': 214,\n",
      " 'pl': 823,\n",
      " 'port': 345,\n",
      " 'portiert': 781,\n",
      " 'portierung': 222,\n",
      " 'ports': 828,\n",
      " 'post': 616,\n",
      " 'posten': 457,\n",
      " 'pr': 297,\n",
      " 'preis': 503,\n",
      " 'premium': 600,\n",
      " 'privat': 226,\n",
      " 'private': 618,\n",
      " 'privaten': 848,\n",
      " 'privatkunden': 693,\n",
      " 'pro': 669,\n",
      " 'probieren': 917,\n",
      " 'probiert': 893,\n",
      " 'problem': 21,\n",
      " 'probleme': 377,\n",
      " 'problemlos': 696,\n",
      " 'produkt': 477,\n",
      " 'produkte': 911,\n",
      " 'protokoll': 972,\n",
      " 'punkt': 647,\n",
      " 'rahmenvertrag': 376,\n",
      " 'raus': 769,\n",
      " 'rde': 43,\n",
      " 'rden': 689,\n",
      " 're': 44,\n",
      " 'reaktion': 651,\n",
      " 'rechner': 933,\n",
      " 'rechnung': 323,\n",
      " 'recht': 332,\n",
      " 'regina': 76,\n",
      " 'rein': 634,\n",
      " 'ren': 132,\n",
      " 'rfen': 266,\n",
      " 'rg': 103,\n",
      " 'rgerlich': 671,\n",
      " 'richtig': 80,\n",
      " 'richtige': 645,\n",
      " 'richtigen': 739,\n",
      " 'rlich': 143,\n",
      " 'ro': 464,\n",
      " 'router': 126,\n",
      " 'rt': 134,\n",
      " 'rufen': 867,\n",
      " 'rufnummer': 204,\n",
      " 'rufnummern': 166,\n",
      " 'rung': 285,\n",
      " 's': 20,\n",
      " 'sache': 412,\n",
      " 'sachverhalt': 796,\n",
      " 'sagen': 123,\n",
      " 'sagt': 596,\n",
      " 'sagte': 523,\n",
      " 'samsung': 709,\n",
      " 'sch': 63,\n",
      " 'schade': 267,\n",
      " 'schalten': 890,\n",
      " 'schaue': 981,\n",
      " 'schauen': 169,\n",
      " 'scheint': 400,\n",
      " 'schicken': 593,\n",
      " 'schildern': 822,\n",
      " 'schilderung': 931,\n",
      " 'schlie': 885,\n",
      " 'schnell': 338,\n",
      " 'schnelle': 443,\n",
      " 'schneller': 925,\n",
      " 'schreiben': 197,\n",
      " 'schrieb': 403,\n",
      " 'schritt': 989,\n",
      " 'schritte': 897,\n",
      " 'schwarz': 993,\n",
      " 'schwer': 978,\n",
      " 'screenshot': 817,\n",
      " 'sehe': 447,\n",
      " 'sehen': 250,\n",
      " 'sehr': 22,\n",
      " 'sein': 11,\n",
      " 'seine': 714,\n",
      " 'seinen': 568,\n",
      " 'seit': 13,\n",
      " 'seite': 257,\n",
      " 'selbst': 202,\n",
      " 'selbstverst': 995,\n",
      " 'sen': 512,\n",
      " 'senden': 220,\n",
      " 'server': 176,\n",
      " 'service': 107,\n",
      " 'setzen': 346,\n",
      " 'shop': 336,\n",
      " 'sicher': 199,\n",
      " 'sicherheit': 613,\n",
      " 'sicherlich': 643,\n",
      " 'siehe': 948,\n",
      " 'sieht': 531,\n",
      " 'sim': 661,\n",
      " 'skysurfer': 650,\n",
      " 'smartphone': 431,\n",
      " 'sms': 288,\n",
      " 'sobald': 211,\n",
      " 'soeben': 835,\n",
      " 'sofort': 350,\n",
      " 'software': 471,\n",
      " 'sogar': 920,\n",
      " 'soll': 62,\n",
      " 'sollen': 524,\n",
      " 'sollte': 58,\n",
      " 'sollten': 553,\n",
      " 'somit': 388,\n",
      " 'sondern': 186,\n",
      " 'sonst': 557,\n",
      " 'sony': 481,\n",
      " 'sophie': 743,\n",
      " 'sowas': 955,\n",
      " 'soweit': 695,\n",
      " 'sowie': 561,\n",
      " 'sp': 554,\n",
      " 'spa': 818,\n",
      " 'speedport': 82,\n",
      " 'splitter': 905,\n",
      " 'sse': 88,\n",
      " 'sselung': 438,\n",
      " 'ssen': 146,\n",
      " 'ssl': 341,\n",
      " 'sst': 291,\n",
      " 'st': 86,\n",
      " 'stand': 679,\n",
      " 'standard': 754,\n",
      " 'standort': 391,\n",
      " 'stehen': 344,\n",
      " 'steht': 157,\n",
      " 'stelle': 240,\n",
      " 'stellen': 416,\n",
      " 'stellt': 701,\n",
      " 'stimmt': 624,\n",
      " 'stunden': 501,\n",
      " 'suche': 984,\n",
      " 'sung': 56,\n",
      " 'super': 398,\n",
      " 'surf': 329,\n",
      " 'surfen': 975,\n",
      " 'svenja': 9,\n",
      " 'sweser': 973,\n",
      " 'system': 242,\n",
      " 'tablet': 573,\n",
      " 'tag': 205,\n",
      " 'tage': 315,\n",
      " 'tagen': 333,\n",
      " 'tarif': 28,\n",
      " 'tarife': 182,\n",
      " 'tarifen': 208,\n",
      " 'tats': 304,\n",
      " 'te': 113,\n",
      " 'team': 183,\n",
      " 'technik': 188,\n",
      " 'techniker': 139,\n",
      " 'technisch': 846,\n",
      " 'technischen': 445,\n",
      " 'telefon': 91,\n",
      " 'telefonanlage': 437,\n",
      " 'telefonanschluss': 787,\n",
      " 'telefone': 510,\n",
      " 'telefonie': 409,\n",
      " 'telefonieren': 260,\n",
      " 'telefonisch': 361,\n",
      " 'ten': 535,\n",
      " 'ter': 571,\n",
      " 'termin': 256,\n",
      " 'thema': 219,\n",
      " 'theme': 480,\n",
      " 'thomas': 750,\n",
      " 'thread': 604,\n",
      " 'tige': 474,\n",
      " 'tigen': 179,\n",
      " 'tigt': 456,\n",
      " 'tigung': 171,\n",
      " 'tipp': 737,\n",
      " 'tipps': 986,\n",
      " 'to': 682,\n",
      " 'tom': 778,\n",
      " 'tot': 826,\n",
      " 'trotz': 740,\n",
      " 'trotzdem': 528,\n",
      " 'tte': 334,\n",
      " 'tun': 360,\n",
      " 'tut': 356,\n",
      " 'tzen': 702,\n",
      " 'tzlich': 309,\n",
      " 'tzt': 638,\n",
      " 'tzung': 944,\n",
      " 'u': 101,\n",
      " 'ude': 887,\n",
      " 'uft': 317,\n",
      " 'uhr': 229,\n",
      " 'umgestellt': 281,\n",
      " 'umstellen': 745,\n",
      " 'umstellung': 194,\n",
      " 'umzug': 467,\n",
      " 'unmut': 889,\n",
      " 'unser': 100,\n",
      " 'unsere': 50,\n",
      " 'unserem': 292,\n",
      " 'unseren': 121,\n",
      " 'unserer': 71,\n",
      " 'unter': 122,\n",
      " 'unternehmen': 440,\n",
      " 'unterst': 289,\n",
      " 'update': 175,\n",
      " 'upload': 359,\n",
      " 'user': 833,\n",
      " 'usw': 707,\n",
      " 'v': 105,\n",
      " 'variante': 627,\n",
      " 'varianten': 862,\n",
      " 'vdsl': 24,\n",
      " 'ver': 435,\n",
      " 'verbindung': 173,\n",
      " 'verbunden': 903,\n",
      " 'verf': 74,\n",
      " 'vergessen': 580,\n",
      " 'verl': 371,\n",
      " 'vermutlich': 775,\n",
      " 'verschiedene': 762,\n",
      " 'verschiedenen': 683,\n",
      " 'verschl': 348,\n",
      " 'verschoben': 949,\n",
      " 'versenden': 623,\n",
      " 'versprochen': 609,\n",
      " 'verst': 856,\n",
      " 'verstanden': 664,\n",
      " 'verstehe': 527,\n",
      " 'verstehen': 641,\n",
      " 'versuche': 873,\n",
      " 'versuchen': 324,\n",
      " 'versucht': 747,\n",
      " 'vertr': 399,\n",
      " 'vertrag': 48,\n",
      " 'vertrags': 950,\n",
      " 'vertragsverl': 560,\n",
      " 'vertrauensvoll': 615,\n",
      " 'verwenden': 771,\n",
      " 'verz': 803,\n",
      " 'viel': 236,\n",
      " 'vielleicht': 77,\n",
      " 'vier': 930,\n",
      " 'vodafone': 298,\n",
      " 'voice': 994,\n",
      " 'voip': 459,\n",
      " 'vom': 95,\n",
      " 'vor': 31,\n",
      " 'voraus': 676,\n",
      " 'vorgang': 594,\n",
      " 'vorhanden': 843,\n",
      " 'vorher': 395,\n",
      " 'vorliegen': 720,\n",
      " 'vorschlag': 938,\n",
      " 'vorstellen': 748,\n",
      " 'vorteil': 786,\n",
      " 'vorteile': 845,\n",
      " 'wann': 318,\n",
      " 'war': 7,\n",
      " 'waren': 479,\n",
      " 'warte': 577,\n",
      " 'warten': 352,\n",
      " 'warteschleife': 987,\n",
      " 'warum': 129,\n",
      " 'wechsel': 597,\n",
      " 'wechseln': 410,\n",
      " 'weder': 656,\n",
      " 'weg': 238,\n",
      " 'wege': 883,\n",
      " 'wegen': 442,\n",
      " 'wei': 218,\n",
      " 'weil': 136,\n",
      " 'weise': 980,\n",
      " 'weiss': 777,\n",
      " 'weiter': 52,\n",
      " 'weitere': 305,\n",
      " 'weiteren': 516,\n",
      " 'weiterhelfen': 799,\n",
      " 'weiterhin': 326,\n",
      " 'welche': 174,\n",
      " 'welchen': 406,\n",
      " 'welcher': 979,\n",
      " 'welches': 331,\n",
      " 'wenden': 213,\n",
      " 'wer': 495,\n",
      " 'werde': 99,\n",
      " 'weshalb': 713,\n",
      " 'wichtig': 587,\n",
      " 'wieso': 809,\n",
      " 'will': 209,\n",
      " 'willkommen': 93,\n",
      " 'windows': 646,\n",
      " 'wirklich': 60,\n",
      " 'wissen': 362,\n",
      " 'wlan': 842,\n",
      " 'wo': 153,\n",
      " 'woche': 210,\n",
      " 'wochen': 382,\n",
      " 'wochenende': 430,\n",
      " 'wohl': 135,\n",
      " 'wollen': 172,\n",
      " 'wollte': 278,\n",
      " 'woran': 779,\n",
      " 'worden': 831,\n",
      " 'wurden': 279,\n",
      " 'www': 389,\n",
      " 'x': 429,\n",
      " 'xl': 924,\n",
      " 'xp': 997,\n",
      " 'xxx': 698,\n",
      " 'yalcin': 295,\n",
      " 'z': 167,\n",
      " 'zahlen': 884,\n",
      " 'zeigen': 990,\n",
      " 'zeit': 150,\n",
      " 'ziel': 690,\n",
      " 'ziemlich': 932,\n",
      " 'zlgbonn': 486,\n",
      " 'zugang': 530,\n",
      " 'zugangsdaten': 322,\n",
      " 'zugesagt': 881,\n",
      " 'zugriff': 907,\n",
      " 'zuk': 666,\n",
      " 'zukommen': 343,\n",
      " 'zukunft': 722,\n",
      " 'zum': 2,\n",
      " 'zumindest': 875,\n",
      " 'zun': 756,\n",
      " 'zus': 466,\n",
      " 'zusammen': 165,\n",
      " 'zust': 836,\n",
      " 'zwar': 203,\n",
      " 'zwei': 251,\n",
      " 'zweite': 880,\n",
      " 'zwischen': 591,\n",
      " 'zyxel': 849}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"res/naive_LM_params.pkl\",\"rb\") as f:\n",
    "    vocab, _, _, _ = pickle.load(f)\n",
    "\n",
    "vocab_lookup = { v: k for k, v in enumerate(vocab) }\n",
    "pprint(vocab_lookup)\n",
    "\n",
    "def embed_simple(word):\n",
    "    if word in vocab_lookup:\n",
    "        return to_categorical(vocab_lookup[word], num_classes=len(vocab_lookup))\n",
    "    \n",
    "    return np.array([0.0]*len(vocab_lookup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(seq, length):\n",
    "    padded = seq\n",
    "    if len(seq) == length:\n",
    "        pass\n",
    "    elif len(seq) > length:\n",
    "        padded = seq[:length]\n",
    "    else:\n",
    "        padded = seq + [\"<PAD>\"] * (length - len(seq))\n",
    "        \n",
    "    return np.array(padded)\n",
    "\n",
    "\n",
    "def logits_to_text(logits, tokenizer):\n",
    "    \"\"\"\n",
    "    Turn logits from a neural network into text using the tokenizer\n",
    "    :param logits: Logits from a neural network\n",
    "    :param tokenizer: Keras Tokenizer fit on the labels\n",
    "    :return: String that represents the text of the logits\n",
    "    \"\"\"\n",
    "    index_to_words = { k: v for k, v in enumerate(vocab) }\n",
    "    index_to_words[0] = '<PAD>'\n",
    "\n",
    "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
    "\n",
    "# def embedding(word):\n",
    "#     if word is \"<PAD>\":\n",
    "#         return pad_vec\n",
    "#     try:\n",
    "#         return lookup_table[word]\n",
    "#     except KeyError:\n",
    "#         return pad_vec\n",
    "    \n",
    "# def word(embedding):\n",
    "#     similarities = [ (cosine_similarity([embedding,], [word_vec,]), word)\n",
    "#             for word, word_vec in lookup_table.items() ]\n",
    "        \n",
    "#     return max(similarities, key=lambda x: x[0])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100000 questions\n",
      "Calculated embeddings (100000, 25, 1000)\n",
      "(100000, 25, 1000)\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "# with open(\"res/forum_1000.txt\",\"r\") as f:\n",
    "with open(\"../umlaute_100000.txt\",\"r\") as f:\n",
    "    for line in f:\n",
    "        questions.append([ word for word in line.replace(\"\\n\", '').split(\" \") ])\n",
    "\n",
    "# questions = questions[:20000]\n",
    "\n",
    "print(\"Loaded \" + str(len(questions)) + \" questions\")\n",
    "        \n",
    "seq_len = max(len(question) for question in questions)\n",
    "\n",
    "embeddings = np.empty((len(questions), 25, len(vocab)))\n",
    "for i in range(len(questions)):\n",
    "    padded = pad_sequence(questions[i], 25)\n",
    "    for j in range(len(padded)):\n",
    "        embeddings[i,j,:] = embed_simple(padded[j])\n",
    "    \n",
    "print(\"Calculated embeddings \" + str(embeddings.shape))\n",
    "pprint(embeddings.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(onehot_x.shape)\n",
    "pprint(preproc_english_sentences.shape)\n",
    "pprint(pad_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 25, 1000)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 128)               867072    \n",
      "_________________________________________________________________\n",
      "repeat_vector_2 (RepeatVecto (None, 25, 128)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, None, 128)         197376    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, None, 1000)        129000    \n",
      "=================================================================\n",
      "Total params: 1,193,448\n",
      "Trainable params: 1,193,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/15\n",
      "80000/80000 [==============================] - 66s - loss: 2.4911e-04 - acc: 0.0035 - val_loss: 2.4379e-04 - val_acc: 0.0020\n",
      "Epoch 2/15\n",
      "80000/80000 [==============================] - 59s - loss: 2.4910e-04 - acc: 0.0027 - val_loss: 2.4378e-04 - val_acc: 0.0020\n",
      "Epoch 3/15\n",
      "80000/80000 [==============================] - 62s - loss: 2.4908e-04 - acc: 0.0027 - val_loss: 2.4376e-04 - val_acc: 0.0020\n",
      "Epoch 4/15\n",
      "80000/80000 [==============================] - 62s - loss: 2.4905e-04 - acc: 0.0027 - val_loss: 2.4372e-04 - val_acc: 0.0020\n",
      "Epoch 5/15\n",
      "80000/80000 [==============================] - 62s - loss: 2.4901e-04 - acc: 0.0027 - val_loss: 2.4370e-04 - val_acc: 0.0020\n",
      "Epoch 6/15\n",
      "80000/80000 [==============================] - 67s - loss: 2.4900e-04 - acc: 0.0027 - val_loss: 2.4370e-04 - val_acc: 0.0020\n",
      "Epoch 7/15\n",
      "80000/80000 [==============================] - 66s - loss: 2.4899e-04 - acc: 0.0028 - val_loss: 2.4370e-04 - val_acc: 0.0029\n",
      "Epoch 8/15\n",
      "80000/80000 [==============================] - 65s - loss: 2.4899e-04 - acc: 0.0034 - val_loss: 2.4369e-04 - val_acc: 0.0026\n",
      "Epoch 9/15\n",
      "80000/80000 [==============================] - 65s - loss: 2.4898e-04 - acc: 0.0032 - val_loss: 2.4368e-04 - val_acc: 0.0028\n",
      "Epoch 10/15\n",
      "80000/80000 [==============================] - 66s - loss: 2.4896e-04 - acc: 0.0035 - val_loss: 2.4366e-04 - val_acc: 0.0030\n",
      "Epoch 11/15\n",
      "80000/80000 [==============================] - 65s - loss: 2.4898e-04 - acc: 0.0031 - val_loss: 2.4370e-04 - val_acc: 0.0020\n",
      "Epoch 12/15\n",
      "80000/80000 [==============================] - 66s - loss: 2.4898e-04 - acc: 0.0030 - val_loss: 2.4367e-04 - val_acc: 0.0024\n",
      "Epoch 13/15\n",
      "80000/80000 [==============================] - 66s - loss: 2.4894e-04 - acc: 0.0033 - val_loss: 2.4367e-04 - val_acc: 0.0017\n",
      "Epoch 14/15\n",
      "80000/80000 [==============================] - 67s - loss: 2.4855e-04 - acc: 0.0036 - val_loss: 2.4276e-04 - val_acc: 0.0041\n",
      "Epoch 15/15\n",
      "80000/80000 [==============================] - 66s - loss: 2.4781e-04 - acc: 0.0043 - val_loss: 2.4209e-04 - val_acc: 0.0038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x7fd8603d0f98>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the neural network\n",
    "ed_model = encoder_decoder_model(embeddings.shape[1:], cell_units=128, layers=1)\n",
    "ed_model.fit(embeddings, embeddings, batch_size=1024, epochs=15, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (1, 17, 228) for Tensor 'input_2:0', which has shape '(?, 25, 1000)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3afa4628026f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrepresentation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0med_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0med_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0monehot_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2475\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2477\u001b[0;31m         **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2478\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1094\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1097\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (1, 17, 228) for Tensor 'input_2:0', which has shape '(?, 25, 1000)'"
     ]
    }
   ],
   "source": [
    "representation = backend.function([ed_model.layers[0].input, backend.learning_phase()], [ed_model.layers[1].output])\n",
    "result = representation([ onehot_x[:1], 0])\n",
    "\n",
    "pprint(result)\n",
    "\n",
    "# Print prediction(s)\n",
    "print(\"Input:\")\n",
    "print(logits_to_text(onehot_x[:1][0], english_tokenizer))\n",
    "print(\"Output:\")\n",
    "print(logits_to_text(ed_model.predict(onehot_x[:1])[0], english_tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
